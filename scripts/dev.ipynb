{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.trainer import ModelParams\n",
    "single_model = ModelParams(\n",
    "        sf_model = [\"single_vertex_model\"], # Input layer: 5 * (2 * spin  + 1), Output layer: forward = 5 + 1, backward = 5\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(64, 32, 16, 8), (64, 32, 32), (64, 16), (64, 64, 16, 16)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [0.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [int(1e3)],\n",
    "        n_iterations = [int(1e4)],\n",
    "        evaluation_batch_size = [int(1e6)],\n",
    "        generate_samples_every_m_training_samples = [int(1e6)],\n",
    ")\n",
    "\n",
    "star_model = ModelParams(\n",
    "        sf_model = [\"star_model\"], # Input layer: 20 * (2 * spin  + 1), Output layer: forward = 20 + 1, backward = 20\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(256, 128, 64, 32), (256, 64, 64, 32), (256, 32), (256, 192, 64, 32)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [1.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [int(1e3)],\n",
    "        n_iterations = [int(1e4)],\n",
    "        evaluation_batch_size = [int(1e6)],\n",
    "        generate_samples_every_m_training_samples = [int(1e6)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.trainer import test_models\n",
    "\n",
    "test_models(single_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models = [single_model, star_model]\n",
    "\n",
    "total_number_of_models = sum(map(len, models))\n",
    "print(f\"Total number of models: {total_number_of_models} to run.\")\n",
    "print(\"Estimated time to run (5 mins per model):\", total_number_of_models * 5 / 60, \"hours\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fields = single_model.fields()\n",
    "\n",
    "for i, params in enumerate(single_model):\n",
    "    print(i, params)\n",
    "    if i > 4:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from core.trainer import train_gfn\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "single_model = ModelParams(\n",
    "        sf_model = [\"single_vertex_model\"], # Input layer: 5 * (2 * spin  + 1), Output layer: forward = 5 + 1, backward = 5\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(64, 32, 16, 8), (64, 32, 32), (64, 16), (64, 64, 16, 16)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [0.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [int(1e1)],\n",
    "        n_iterations = [int(1e1)],\n",
    "        evaluation_batch_size = [int(1e1)],\n",
    "        generate_samples_every_m_training_samples = [int(1e3)],\n",
    ")\n",
    "\n",
    "star_model = ModelParams(\n",
    "        sf_model = [\"star_model\"], # Input layer: 20 * (2 * spin  + 1), Output layer: forward = 20 + 1, backward = 20\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(256, 128, 64, 32), (256, 64, 64, 32), (256, 32), (256, 192, 64, 32)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [1.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [int(1e1)],\n",
    "        n_iterations = [int(1e1)],\n",
    "        evaluation_batch_size = [int(1e1)],\n",
    "        generate_samples_every_m_training_samples = [int(1e3)],\n",
    ")\n",
    "\n",
    "models = [single_model, star_model]\n",
    "\n",
    "total_number_of_models = sum(map(len, models))\n",
    "total_number_of_models = sum(map(len, models))\n",
    "tf.print(f\"Total number of models:\", total_number_of_models)\n",
    "tf.print(f\"Expected time to complete (5 mins per model):\", total_number_of_models * 5 / 60, \"hours\")\n",
    "\n",
    "models_avg_losses = {\n",
    "    model.sf_model[0]: []\n",
    "    for model in models\n",
    "}\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "tf.print(\"Starting testing:\", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), \"\\n\")\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "# import numpy as np\n",
    "for model in models:\n",
    "    num_models = len(model)\n",
    "    tf.print(\"Testing model:\", model.sf_model[0], \"\\n\")\n",
    "    with open(f\"results/{model.sf_model[0]}-params.pkl\", \"wb\") as f:\n",
    "        f.write(b\"training_time, params, avg_losses\\n\")\n",
    "    for i, params in enumerate(model):\n",
    "        tf.print(f\"Starting training for parameter set {i} of {num_models}\")\n",
    "        training_start = datetime.datetime.now()\n",
    "        avg_losses = train_gfn(**params)\n",
    "        # avg_losses = np.random.rand(10)\n",
    "        training_time = (datetime.datetime.now() - training_start).total_seconds()\n",
    "        tf.print(\"Finished training, elapsed time:\", training_time / 60, \"minutes\\n\")\n",
    "        models_avg_losses[model.sf_model[0]].append((training_time, avg_losses, params))\n",
    "\n",
    "        with open(f\"results/{model.sf_model[0]}-params.pkl\", \"ab\") as f:\n",
    "            pickle.dump((training_time, params, avg_losses), f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "with open(\"results/single_vertex_model-params.pkl\", \"rb\") as f:\n",
    "    header = f.readline()\n",
    "    while True:\n",
    "        try:\n",
    "            data = pickle.load(f)\n",
    "            print(data)\n",
    "        except EOFError:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
