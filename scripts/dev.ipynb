{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "\n",
    "@dataclass\n",
    "class ModelParams:\n",
    "    spin_j: float \n",
    "    sf_model: str\n",
    "    main_layer_hidden_nodes: tuple\n",
    "    branch1_hidden_nodes: tuple\n",
    "    branch2_hidden_nodes: tuple\n",
    "    activation: str\n",
    "    exploration_rate: float\n",
    "    training_fraction_from_back_traj: float\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    n_iterations: int\n",
    "    evaluation_batch_size: int\n",
    "    generate_samples_every_m_training_samples: int\n",
    "    \n",
    "    def fields(self):\n",
    "        return list(self.__dataclass_fields__.keys())\n",
    "\n",
    "    def params(self):\n",
    "        return (getattr(self, field, ()) for field in self.fields())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(list(itertools.product(*self.params())))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        for param in itertools.product(*self.params()):\n",
    "            return {\n",
    "                key: value\n",
    "                for key, value in zip(self.fields(), param)\n",
    "            }\n",
    "            \n",
    "        raise StopIteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model = ModelParams(\n",
    "        sf_model = [\"single_vertex_model\"], # Input layer: 5 * (2 * spin  + 1), Output layer: forward = 5 + 1, backward = 5\n",
    "        spin_j = [3, 4, 5, 6],\n",
    "        main_layer_hidden_nodes = [(64, 32, 16, 8), (64, 32, 32), (64, 16), (64, 64, 16, 16)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [0.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [1e3],\n",
    "        n_iterations = [1e4],\n",
    "        evaluation_batch_size = [1e6],\n",
    "        generate_samples_every_m_training_samples = [1e6],\n",
    ")\n",
    "\n",
    "star_model = ModelParams(\n",
    "        sf_model = [\"star_model\"],\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(256, 128, 64, 32), (256, 64, 64, 32), (256, 192, 64, 32)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [1.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [1e3],\n",
    "        n_iterations = [1e4],\n",
    "        evaluation_batch_size = [1e6],\n",
    "        generate_samples_every_m_training_samples = [1e6],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 66 to run.\n",
      "Estimated time to run (5 mins per model): 5.5 hours\n"
     ]
    }
   ],
   "source": [
    "models = [single_model, star_model]\n",
    "\n",
    "total_number_of_models = sum(map(len, models))\n",
    "print(f\"Total number of models: {total_number_of_models} to run.\")\n",
    "print(\"Estimated time to run (5 mins per model):\", total_number_of_models * 5 / 60, \"hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n"
     ]
    }
   ],
   "source": [
    "fields = single_model.fields()\n",
    "\n",
    "for i, params in enumerate(single_model):\n",
    "    print(params)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 48 to run.\n",
      "Expected time to complete: 4.0 hours.\n",
      "Starting testing... 2023-05-09 17:56:17\n",
      "Testing model: single_vertex_model\n",
      "Starting param set 0 of 24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jared\\OneDrive\\Github\\GFlowNets_on_SpinFoams\\scripts\\dev.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 93>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jared/OneDrive/Github/GFlowNets_on_SpinFoams/scripts/dev.ipynb#W5sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, params \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(model):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jared/OneDrive/Github/GFlowNets_on_SpinFoams/scripts/dev.ipynb#W5sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting param set \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mnum_models\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jared/OneDrive/Github/GFlowNets_on_SpinFoams/scripts/dev.ipynb#W5sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m         ave_losses \u001b[39m=\u001b[39m train_gfn(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, include_datetime_in_directory_name\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jared/OneDrive/Github/GFlowNets_on_SpinFoams/scripts/dev.ipynb#W5sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m         ave_losses[model\u001b[39m.\u001b[39msf_model]\u001b[39m.\u001b[39mappend((params, ave_losses))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jared/OneDrive/Github/GFlowNets_on_SpinFoams/scripts/dev.ipynb#W5sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinished testing... \u001b[39m\u001b[39m\"\u001b[39m, datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\users\\jared\\onedrive\\github\\gflownets_on_spinfoams\\core\\trainer.py:143\u001b[0m, in \u001b[0;36mtrain_gfn\u001b[1;34m(spin_j, sf_model, main_layer_hidden_nodes, branch1_hidden_nodes, branch2_hidden_nodes, activation, exploration_rate, training_fraction_from_back_traj, learning_rate, batch_size, n_iterations, evaluation_batch_size, generate_samples_every_m_training_samples, include_datetime_in_directory_name)\u001b[0m\n\u001b[0;32m    130\u001b[0m     directory_for_generated_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining run on \u001b[39m\u001b[39m{\u001b[39;00mtraining_run_datetime\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m runner \u001b[39m=\u001b[39m Runner(\n\u001b[0;32m    133\u001b[0m     spinfoam_model\u001b[39m=\u001b[39mspinfoam_model,\n\u001b[0;32m    134\u001b[0m     main_layer_hidden_nodes\u001b[39m=\u001b[39mmain_layer_hidden_nodes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     learning_rate\u001b[39m=\u001b[39mlearning_rate\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 143\u001b[0m ave_losses \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39;49mtrain_agent(\n\u001b[0;32m    144\u001b[0m     batch_size, n_iterations, \n\u001b[0;32m    145\u001b[0m     evaluation_batch_size, generate_samples_every_m_training_samples,\n\u001b[0;32m    146\u001b[0m     directory_for_generated_samples\n\u001b[0;32m    147\u001b[0m )\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m ave_losses\n",
      "File \u001b[1;32mc:\\users\\jared\\onedrive\\github\\gflownets_on_spinfoams\\core\\runner.py:77\u001b[0m, in \u001b[0;36mRunner.train_agent\u001b[1;34m(self, training_batch_size, n_iterations, evaluation_batch_size, generate_samples_every_m_training_samples, directory_for_generated_samples)\u001b[0m\n\u001b[0;32m     75\u001b[0m evaluation_batch_size \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(evaluation_batch_size)\n\u001b[0;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mrange(n_iterations):\n\u001b[1;32m---> 77\u001b[0m     ave_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_training_step(n_batch_forwards, n_batch_backwards)\n\u001b[0;32m     78\u001b[0m     ave_losses \u001b[39m=\u001b[39m ave_losses\u001b[39m.\u001b[39mwrite(i, ave_loss)\n\u001b[0;32m     80\u001b[0m     trained_on_k_samples \u001b[39m=\u001b[39m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m training_batch_size\n",
      "File \u001b[1;32mc:\\Users\\Jared\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Jared\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Jared\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Jared\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Jared\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Jared\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Jared\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from core.trainer import train_gfn\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "@dataclass\n",
    "class ModelParams:\n",
    "    spin_j: float \n",
    "    sf_model: str\n",
    "    main_layer_hidden_nodes: tuple\n",
    "    branch1_hidden_nodes: tuple\n",
    "    branch2_hidden_nodes: tuple\n",
    "    activation: str\n",
    "    exploration_rate: float\n",
    "    training_fraction_from_back_traj: float\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    n_iterations: int\n",
    "    evaluation_batch_size: int\n",
    "    generate_samples_every_m_training_samples: int\n",
    "    \n",
    "    def fields(self):\n",
    "        return list(self.__dataclass_fields__.keys())\n",
    "    \n",
    "    def params(self):\n",
    "        return (getattr(self, field, ()) for field in self.fields())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(list(itertools.product(*self.params())))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):        \n",
    "        for param in itertools.product(*self.params()):\n",
    "            return {\n",
    "                key: value\n",
    "                for key, value in zip(self.fields(), param)\n",
    "            }\n",
    "            \n",
    "        raise StopIteration \n",
    "\n",
    "single_model = ModelParams(\n",
    "        sf_model = [\"single_vertex_model\"], # Input layer: 5 * (2 * spin  + 1), Output layer: forward = 5 + 1, backward = 5\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(64, 32, 16, 8), (64, 32, 32), (64, 16), (64, 64, 16, 16)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [0.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [int(1e3)],\n",
    "        n_iterations = [int(1e4)],\n",
    "        evaluation_batch_size = [int(1e6)],\n",
    "        generate_samples_every_m_training_samples = [int(1e6)],\n",
    ")\n",
    "\n",
    "star_model = ModelParams(\n",
    "        sf_model = [\"star_model\"], # Input layer: 20 * (2 * spin  + 1), Output layer: forward = 20 + 1, backward = 20\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(256, 128, 64, 32), (256, 64, 64, 32), (256, 32), (256, 192, 64, 32)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [1.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [int(1e3)],\n",
    "        n_iterations = [int(1e4)],\n",
    "        evaluation_batch_size = [int(1e6)],\n",
    "        generate_samples_every_m_training_samples = [int(1e6)],\n",
    ")\n",
    "\n",
    "models = [single_model, star_model]\n",
    "\n",
    "total_number_of_models = sum(map(len, models))\n",
    "total_number_of_models = sum(map(len, models))\n",
    "print(f\"Total number of models: {total_number_of_models} to run.\")\n",
    "print(f\"Expected time to complete: {total_number_of_models * 5 / 60} hours.\")\n",
    "\n",
    "ave_losses = {\n",
    "    \"single_vertex_model\": [],\n",
    "    \"star_model\": [],\n",
    "}\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print(f\"Starting testing... {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "for model in models:\n",
    "    num_models = len(model)\n",
    "    print(\"Testing model:\", model.sf_model[0])\n",
    "    for i, params in enumerate(model):\n",
    "        print(f\"Starting training for parameter set {i} of {num_models}\")\n",
    "        ave_losses = train_gfn(**params, include_datetime_in_directory_name=False)\n",
    "        ave_losses[model.sf_model[0]].append((params, ave_losses))\n",
    "\n",
    "print(\"Finished testing... \", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print(\"Total time taken: \", datetime.datetime.now() - start)\n",
    "print(\"Saving results...\")\n",
    "\n",
    "with open(\"ave_losses.pickle\", \"wb\") as f:\n",
    "    pickle.dump(ave_losses, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
