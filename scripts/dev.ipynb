{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "\n",
    "@dataclass\n",
    "class ModelParams:\n",
    "    spin_j: float \n",
    "    sf_model: str\n",
    "    main_layer_hidden_nodes: tuple\n",
    "    branch1_hidden_nodes: tuple\n",
    "    branch2_hidden_nodes: tuple\n",
    "    activation: str\n",
    "    exploration_rate: float\n",
    "    training_fraction_from_back_traj: float\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    n_iterations: int\n",
    "    evaluation_batch_size: int\n",
    "    generate_samples_every_m_training_samples: int\n",
    "    \n",
    "    def fields(self):\n",
    "        return list(self.__dataclass_fields__.keys())\n",
    "\n",
    "    def params(self):\n",
    "        return (getattr(self, field, ()) for field in self.fields())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(list(itertools.product(*self.params())))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        for param in itertools.product(*self.params()):\n",
    "            return {\n",
    "                key: value\n",
    "                for key, value in zip(self.fields(), param)\n",
    "            }\n",
    "            \n",
    "        raise StopIteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model = ModelParams(\n",
    "        sf_model = [\"single_vertex_model\"], # Input layer: 5 * (2 * spin  + 1), Output layer: forward = 5 + 1, backward = 5\n",
    "        spin_j = [3, 4, 5, 6],\n",
    "        main_layer_hidden_nodes = [(64, 32, 16, 8), (64, 32, 32), (64, 16), (64, 64, 16, 16)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [0.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [1e3],\n",
    "        n_iterations = [1e4],\n",
    "        evaluation_batch_size = [1e6],\n",
    "        generate_samples_every_m_training_samples = [1e6],\n",
    ")\n",
    "\n",
    "star_model = ModelParams(\n",
    "        sf_model = [\"star_model\"],\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(256, 128, 64, 32), (256, 64, 64, 32), (256, 192, 64, 32)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [1.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [1e3],\n",
    "        n_iterations = [1e4],\n",
    "        evaluation_batch_size = [1e6],\n",
    "        generate_samples_every_m_training_samples = [1e6],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 66 to run.\n",
      "Estimated time to run (5 mins per model): 5.5 hours\n"
     ]
    }
   ],
   "source": [
    "models = [single_model, star_model]\n",
    "\n",
    "total_number_of_models = sum(map(len, models))\n",
    "print(f\"Total number of models: {total_number_of_models} to run.\")\n",
    "print(\"Estimated time to run (5 mins per model):\", total_number_of_models * 5 / 60, \"hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n",
      "{'spin_j': 3, 'sf_model': 'single_vertex_model', 'main_layer_hidden_nodes': (64, 32, 16, 8), 'branch1_hidden_nodes': (), 'branch2_hidden_nodes': (), 'activation': 'swish', 'exploration_rate': 0.5, 'training_fraction_from_back_traj': 0.0, 'learning_rate': 0.0005, 'batch_size': 1000.0, 'n_iterations': 10000.0, 'evaluation_batch_size': 1000000.0, 'generate_samples_every_m_training_samples': 1000000.0}\n"
     ]
    }
   ],
   "source": [
    "fields = single_model.fields()\n",
    "\n",
    "for i, params in enumerate(single_model):\n",
    "    print(params)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 48 to run.\n",
      "Expected time to complete: 4.0 hours.\n"
     ]
    }
   ],
   "source": [
    "# from core.trainer import train_gfn\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "@dataclass\n",
    "class ModelParams:\n",
    "    spin_j: float \n",
    "    sf_model: str\n",
    "    main_layer_hidden_nodes: tuple\n",
    "    branch1_hidden_nodes: tuple\n",
    "    branch2_hidden_nodes: tuple\n",
    "    activation: str\n",
    "    exploration_rate: float\n",
    "    training_fraction_from_back_traj: float\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    n_iterations: int\n",
    "    evaluation_batch_size: int\n",
    "    generate_samples_every_m_training_samples: int\n",
    "    \n",
    "    def fields(self):\n",
    "        return list(self.__dataclass_fields__.keys())\n",
    "    \n",
    "    def params(self):\n",
    "        return (getattr(self, field, ()) for field in self.fields())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(list(itertools.product(*self.params())))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):        \n",
    "        for param in itertools.product(*self.params()):\n",
    "            return {\n",
    "                key: value\n",
    "                for key, value in zip(self.fields(), param)\n",
    "            }\n",
    "            \n",
    "        raise StopIteration \n",
    "\n",
    "single_model = ModelParams(\n",
    "        sf_model = [\"single_vertex_model\"], # Input layer: 5 * (2 * spin  + 1), Output layer: forward = 5 + 1, backward = 5\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(64, 32, 16, 8), (64, 32, 32), (64, 16), (64, 64, 16, 16)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [0.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [1e3],\n",
    "        n_iterations = [1e4],\n",
    "        evaluation_batch_size = [1e6],\n",
    "        generate_samples_every_m_training_samples = [1e6],\n",
    ")\n",
    "\n",
    "star_model = ModelParams(\n",
    "        sf_model = [\"star_model\"],\n",
    "        spin_j = [3.5, 6.5],\n",
    "        main_layer_hidden_nodes = [(256, 128, 64, 32), (256, 64, 64, 32), (256, 32), (256, 192, 64, 32)],\n",
    "        branch1_hidden_nodes = [()],\n",
    "        branch2_hidden_nodes = [()],\n",
    "        activation = [\"swish\", \"tanh\", \"relu\"],\n",
    "        exploration_rate = [0.5],\n",
    "        training_fraction_from_back_traj = [1.0],\n",
    "        learning_rate = [0.0005],\n",
    "        batch_size = [1e3],\n",
    "        n_iterations = [1e4],\n",
    "        evaluation_batch_size = [1e6],\n",
    "        generate_samples_every_m_training_samples = [1e6],\n",
    ")\n",
    "\n",
    "models = [single_model, star_model]\n",
    "\n",
    "total_number_of_models = sum(map(len, models))\n",
    "total_number_of_models = sum(map(len, models))\n",
    "print(f\"Total number of models: {total_number_of_models} to run.\")\n",
    "print(f\"Expected time to complete: {total_number_of_models * 5 / 60} hours.\")\n",
    "\n",
    "ave_losses = {\n",
    "    \"single_vertex_model\": [],\n",
    "    \"star_model\": [],\n",
    "}\n",
    "\n",
    "# start = datetime.datetime.now()\n",
    "# print(f\"Starting testing... {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# for model in models:\n",
    "#     print(\"Testing model: \", model.sf_model)\n",
    "#     for i, params in enumerate(model):\n",
    "#         ave_losses = train_gfn(**params)\n",
    "#         ave_losses[model.sf_model].append((params, ave_losses))\n",
    "\n",
    "# print(\"Finished testing... \", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# print(\"Total time taken: \", datetime.datetime.now() - start)\n",
    "# print(\"Saving results...\")\n",
    "\n",
    "# with open(\"ave_losses.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(ave_losses, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
