{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16eed45f-9117-4ee4-82dd-67c9903fbc47",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8db862ce-aece-4e7d-8fef-3c5bc304220b",
   "metadata": {},
   "source": [
    "## Importing libs and setting plot style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5a467a-00c4-4ab4-bba0-53f0bc9d3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from atpbar import atpbar, flush\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b1a0e6-318b-4f06-acfd-47eadcaa0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting plot style\n",
    "\n",
    "sns.set()\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 2.0})\n",
    "\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_style(\n",
    "    \"whitegrid\",\n",
    "    {\n",
    "        \"axes.edgecolor\": \"black\",\n",
    "        \"axes.grid\": True,\n",
    "        \"axes.axisbelow\": True,\n",
    "        \"axes.labelcolor\": \".15\",\n",
    "        \"grid.color\": \"0.9\",\n",
    "        \"grid.linestyle\": \"-\",\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"xtick.bottom\": True,\n",
    "        \"xtick.top\": True,\n",
    "        \"ytick.left\": True,\n",
    "        \"ytick.right\": True,\n",
    "        \"font.family\": [\"sans-serif\"],\n",
    "        \"font.sans-serif\": [\"Liberation Sans\", \"Bitstream Vera Sans\", \"sans-serif\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70b36922-790a-445c-b873-0421dacab698",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c4fe1e-49bb-4837-a26c-74c60fceb985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal number of threads: 12\n"
     ]
    }
   ],
   "source": [
    "# folder with stored data\n",
    "data_folder = \"../../data\"\n",
    "\n",
    "# GFlowNet parameters\n",
    "spin_list = [2.0]\n",
    "iteration_list = [int(1e4) for i in range(0, 1)]\n",
    "main_layer_hidden_nodes_list = [(30, 20) for i in range(0, 1)]\n",
    "evaluation_batch_size_list = [int(1e6) for i in range(0, 1)]\n",
    "training_batch_size_list = [int(1e3) for i in range(0, 1)]\n",
    "generate_samples_every_training_samples_list = [int(1e6) for i in range(0, 1)]\n",
    "\n",
    "model = \"single_vertex_model\"\n",
    "branch1_hidden_nodes = ()\n",
    "branch2_hidden_nodes = ()\n",
    "activation = \"swish\"\n",
    "exploration_rate = 0.5\n",
    "training_fraction_from_back_traj = 0.0\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# set optimal number of threads\n",
    "optimal_number_of_threads = int(mp.cpu_count())\n",
    "print(f\"optimal number of threads: {optimal_number_of_threads}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99a6354b-9fae-42f9-9413-acbfdf797ab6",
   "metadata": {},
   "source": [
    "# Angles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bd73c9b-c09d-4eee-8c36-008a8ec6d39b",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8381bf-7a92-4be8-8107-3f2634fc1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes an intertwiner and returns the corresponding angle eigenvalue\n",
    "\n",
    "def from_intertwiner_to_angle(matrix_element, spin):\n",
    "    return (matrix_element * (matrix_element + 1) - 2 * spin * (spin + 1)) / (\n",
    "        2 * spin * (spin + 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe0ab0a-333b-4a89-bdac-0b0cb6bf1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_draws_to_angles(\n",
    "    folder_prefix,\n",
    "    spin,\n",
    "    sample_name,\n",
    "    dihedral_angle_path,\n",
    "    n,\n",
    "    name,\n",
    "):\n",
    "    for i in atpbar(range(n), name=name):\n",
    "        time.sleep(0.0001)\n",
    "\n",
    "    sample_path = f\"{folder_prefix}/samples/{sample_name}\"\n",
    "\n",
    "    # load in memory the stored draws\n",
    "    df = pd.read_csv(sample_path, low_memory=False)\n",
    "    df.columns = df.columns.str.replace(\"intertwiner \", \"node \", regex=True)\n",
    "\n",
    "    # from intertwiners to angles\n",
    "    df.iloc[:, :5] = df.iloc[:, :5].apply(from_intertwiner_to_angle, args=(spin,))\n",
    "\n",
    "    ##########################################################\n",
    "    # Computing exp values (avg)\n",
    "    ##########################################################\n",
    "\n",
    "    df_final = pd.concat([df.mean()], axis=1)\n",
    "    df_final.columns = [\"cosine angle avg\"]\n",
    "\n",
    "    angle_exp_values_path_batch = f\"{dihedral_angle_path}/{name}\"\n",
    "    # os.makedirs(f\"{angle_exp_values_path_batch}\", exist_ok=True)\n",
    "    df_final.to_csv(angle_exp_values_path_batch, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4fb098-86fb-4d41-ad0a-b908d55af39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts multiple samples into dihedral angles.\n",
    "# Store the result for each batch, then combines all batchs in another CSV file\n",
    "\n",
    "def angles_compute(\n",
    "    data_folder,\n",
    "    model,\n",
    "    spin,\n",
    "    total_iterations,\n",
    "    main_layer_hidden_nodes,\n",
    "    evaluation_batch_size,\n",
    "    generate_samples_every_training_samples,\n",
    "    batch_size,\n",
    "    activation_function=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    training_fraction_from_back_traj=0.0,\n",
    "    learning_rate=0.0005,\n",
    "    number_of_threads=optimal_number_of_threads,\n",
    "):\n",
    "    folder_prefix = Path(\n",
    "        f\"{data_folder}/\",\n",
    "        f\"GFlowNet/{model}/j_{spin}/n_iterations_{total_iterations}/\",\n",
    "        f\"main_layer_hid_nodes_{main_layer_hidden_nodes}/exploration_rate_{exploration_rate}/learning_rate_{learning_rate}/\",\n",
    "        f\"batch_size_{batch_size}/\",\n",
    "    )\n",
    "\n",
    "    batch_sample_path_collection = []\n",
    "\n",
    "    for i in range(total_iterations):\n",
    "        trained_on_k_samples = (i + 1) * batch_size\n",
    "\n",
    "        if trained_on_k_samples % generate_samples_every_training_samples == 0:\n",
    "            sample_name = Path(\n",
    "                f\"Gen_samples_epoch_#{i + 1}\"\n",
    "                f\"_after_learn_from_{trained_on_k_samples}\"\n",
    "                \"_train_samples.csv\",\n",
    "            )\n",
    "\n",
    "            if os.path.isfile(f\"{folder_prefix}/samples/{sample_name}\"):\n",
    "                batch_sample_path_collection.append(sample_name)\n",
    "\n",
    "            else:\n",
    "                warnings.warn(\"Warning: the sample %s was not found\" % (sample_name))\n",
    "\n",
    "    batches_to_assemble = len(batch_sample_path_collection)\n",
    "\n",
    "    if batches_to_assemble != 0:\n",
    "        print(f\"{batches_to_assemble} sample batches to process\")\n",
    "\n",
    "        dihedral_angle_path = f\"{folder_prefix}/operators/angles\"\n",
    "\n",
    "        os.makedirs(f\"{dihedral_angle_path}\", exist_ok=True)\n",
    "\n",
    "        print(\n",
    "            f\"\\nComputing exp. values and autocorrelations of {batches_to_assemble} sample batches, using {number_of_threads} threads...\\n\"\n",
    "        )\n",
    "\n",
    "        threads = []\n",
    "\n",
    "        for sample_name in batch_sample_path_collection:\n",
    "            name = \"angles_{}\".format(sample_name)\n",
    "            n = random.randint(number_of_threads, 10000)\n",
    "\n",
    "            t = threading.Thread(\n",
    "                target=from_draws_to_angles,\n",
    "                args=(\n",
    "                    folder_prefix,\n",
    "                    spin,\n",
    "                    sample_name,\n",
    "                    dihedral_angle_path,\n",
    "                    n,\n",
    "                    name,\n",
    "                ),\n",
    "            )\n",
    "            threads.append(t)\n",
    "            t.start()\n",
    "\n",
    "        # wait for the threads to complete\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "        flush()\n",
    "\n",
    "        print(f\"All samples in all batches have been processed\")\n",
    "\n",
    "        print(f\"\\nAssembling {batches_to_assemble} batches...\")\n",
    "\n",
    "        ##########################################################\n",
    "        ### Assembling expectation values\n",
    "        ##########################################################\n",
    "\n",
    "        DF_list = [\n",
    "            pd.read_csv(\n",
    "                f\"{dihedral_angle_path}/angles_{sample_name}\",\n",
    "                index_col=0,\n",
    "                low_memory=False,\n",
    "            )\n",
    "            for sample_name in batch_sample_path_collection\n",
    "        ]\n",
    "\n",
    "        df_all_batches = pd.concat(\n",
    "            DF_list[:], axis=1, keys=batch_sample_path_collection\n",
    "        )\n",
    "\n",
    "        df_all_batches.columns = df_all_batches.columns.droplevel(-1)\n",
    "\n",
    "        df_all_batches.T\n",
    "\n",
    "        df_all_batches.to_csv(\n",
    "            f\"{dihedral_angle_path}/batches_assembled_{batches_to_assemble}.csv\",\n",
    "            index=True,\n",
    "        )\n",
    "\n",
    "        print(\"Done\")\n",
    "\n",
    "    else:\n",
    "        warnings.warn(\"I can't compute angles since there are no samples available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b404de98-a6d7-4a8d-8798-0521b5975d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 sample batches to process\n",
      "\n",
      "Computing exp. values and autocorrelations of 10 sample batches, using 12 threads...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8343219a7fb74e828f3a0fe8b1b38cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples in all batches have been processed\n",
      "\n",
      "Assembling 10 batches...\n",
      "        Gen_samples_epoch_#1000_after_learn_from_1000000_train_samples.csv  \\\n",
      "node 5                                          -0.729320                    \n",
      "node 4                                          -0.351705                    \n",
      "node 3                                          -0.326573                    \n",
      "node 2                                          -0.745431                    \n",
      "node 1                                          -0.084806                    \n",
      "\n",
      "        Gen_samples_epoch_#2000_after_learn_from_2000000_train_samples.csv  \\\n",
      "node 5                                          -0.524196                    \n",
      "node 4                                          -0.357558                    \n",
      "node 3                                          -0.264184                    \n",
      "node 2                                          -0.666719                    \n",
      "node 1                                          -0.184463                    \n",
      "\n",
      "        Gen_samples_epoch_#3000_after_learn_from_3000000_train_samples.csv  \\\n",
      "node 5                                          -0.413364                    \n",
      "node 4                                          -0.434904                    \n",
      "node 3                                          -0.284729                    \n",
      "node 2                                          -0.675952                    \n",
      "node 1                                          -0.275892                    \n",
      "\n",
      "        Gen_samples_epoch_#4000_after_learn_from_4000000_train_samples.csv  \\\n",
      "node 5                                          -0.358077                    \n",
      "node 4                                          -0.349675                    \n",
      "node 3                                          -0.338728                    \n",
      "node 2                                          -0.356610                    \n",
      "node 1                                          -0.322578                    \n",
      "\n",
      "        Gen_samples_epoch_#5000_after_learn_from_5000000_train_samples.csv  \\\n",
      "node 5                                          -0.343079                    \n",
      "node 4                                          -0.332371                    \n",
      "node 3                                          -0.348915                    \n",
      "node 2                                          -0.341420                    \n",
      "node 1                                          -0.337272                    \n",
      "\n",
      "        Gen_samples_epoch_#6000_after_learn_from_6000000_train_samples.csv  \\\n",
      "node 5                                          -0.342858                    \n",
      "node 4                                          -0.337600                    \n",
      "node 3                                          -0.334032                    \n",
      "node 2                                          -0.365278                    \n",
      "node 1                                          -0.344600                    \n",
      "\n",
      "        Gen_samples_epoch_#7000_after_learn_from_7000000_train_samples.csv  \\\n",
      "node 5                                          -0.347591                    \n",
      "node 4                                          -0.349022                    \n",
      "node 3                                          -0.348351                    \n",
      "node 2                                          -0.353122                    \n",
      "node 1                                          -0.334708                    \n",
      "\n",
      "        Gen_samples_epoch_#8000_after_learn_from_8000000_train_samples.csv  \\\n",
      "node 5                                          -0.352031                    \n",
      "node 4                                          -0.318288                    \n",
      "node 3                                          -0.330053                    \n",
      "node 2                                          -0.329946                    \n",
      "node 1                                          -0.329819                    \n",
      "\n",
      "        Gen_samples_epoch_#9000_after_learn_from_9000000_train_samples.csv  \\\n",
      "node 5                                          -0.353056                    \n",
      "node 4                                          -0.331950                    \n",
      "node 3                                          -0.335687                    \n",
      "node 2                                          -0.335024                    \n",
      "node 1                                          -0.322828                    \n",
      "\n",
      "        Gen_samples_epoch_#10000_after_learn_from_10000000_train_samples.csv  \n",
      "node 5                                          -0.336813                     \n",
      "node 4                                          -0.343597                     \n",
      "node 3                                          -0.335692                     \n",
      "node 2                                          -0.347152                     \n",
      "node 1                                          -0.355293                     \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for (\n",
    "    spin,\n",
    "    total_iterations,\n",
    "    main_layer_hidden_nodes,\n",
    "    evaluation_batch_size,\n",
    "    training_batch_size,\n",
    "    generate_samples_every_training_samples,\n",
    ") in zip(\n",
    "    spin_list,\n",
    "    iteration_list,\n",
    "    main_layer_hidden_nodes_list,\n",
    "    evaluation_batch_size_list,\n",
    "    training_batch_size_list,\n",
    "    generate_samples_every_training_samples_list,\n",
    "):\n",
    "    angles_compute(\n",
    "        data_folder,\n",
    "        model,\n",
    "        spin,\n",
    "        total_iterations,\n",
    "        main_layer_hidden_nodes,\n",
    "        evaluation_batch_size,\n",
    "        generate_samples_every_training_samples,\n",
    "        training_batch_size,\n",
    "        activation_function=\"swish\",\n",
    "        exploration_rate=0.5,\n",
    "        training_fraction_from_back_traj=0.0,\n",
    "        learning_rate=0.0005,\n",
    "        number_of_threads=optimal_number_of_threads,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21d0659c",
   "metadata": {},
   "source": [
    "# TODO: continue from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
