{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37162d5-8c51-43cf-adbe-11ba98e33585",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d71e80-fee1-4ac0-8ba8-ec9807d2c82e",
   "metadata": {},
   "source": [
    "Let's consider a quantity $O$ which can be computed as:\n",
    "\n",
    "$$\n",
    "O = \\sum\\limits_{x \\in \\chi} o \\left( x \\right) \\tilde{f} \\left( x \\right) \\ ,\n",
    "$$\n",
    "\n",
    "where $x$ is a (possibly multidimensional) discrete variable on a state space $\\chi$ which must be summed over, while $\\tilde{f}$ is a probability density function on $\\chi$, so that $\\sum\\limits_{x \\in \\chi} \\tilde{f} \\left( x \\right) = 1$. From now on, we define $\\tilde{f}$ as the $\\textbf{target}$ distribution and we omit the state space label $\\chi$. Since the target distribution is normalized, we can write:\n",
    "\n",
    "$$\n",
    "\\tilde{f} \\left( x \\right) \\equiv \\frac{f \\left( x \\right)}{\\sum\\limits_{x} f \\left( x \\right)} \\ ,\n",
    "$$\n",
    "\n",
    "from which:\n",
    "\n",
    "$$\n",
    "O = \\frac{ \\sum\\limits_{x} f \\left( x \\right) o \\left( x \\right) }{\\sum\\limits_{x} f \\left( x \\right)} \\ .\n",
    "$$\n",
    "\n",
    "If the target distribution is computable up to a multiplying constant, the $\\textbf{Metropolis–Hastings algorithm}$ allows to construct on state space $\\chi$ an ergodic Markov chain with length $N_{MC}$: $x_{1} , \\ x_{2} , \\ x_{3} \\dots , x_{n} \\ \\dots , x_{N_{MC}}$ such that $x_{n}$ is converging (in distribution) to $\\tilde{f}$, exploring the space $\\chi$ progressively. If we define:\n",
    "\n",
    "$$\n",
    "O_{N_{MC}} = \\frac{1}{N_{MC}} \\sum\\limits_{i = 1}^{N_{MC}} o \\left(x_i \\right) \\ ,\n",
    "$$\n",
    "\n",
    "then, since the chain can be considered as a statistical sample, the law of large numbers ensures that:\n",
    "\n",
    "$$\n",
    "\\lim_{N_{MC} \\to \\infty} O_{N_{MC}}  = O \\ ,\n",
    "$$\n",
    "\n",
    "which allows us to write:\n",
    "\n",
    "$$\n",
    "O_{N_{MC}} \\approx O \\hspace{3mm} \\textrm{for $N_{MC} \\gg 1$} \\ .\n",
    "$$\n",
    "\n",
    "Namely, we end up with an estimate of the original sum. Since the simulation is Markovian and the chain itself can be considered as a statistical sample, the latter usually depends on the starting value. The initial steps are tipically removed as $\\textbf{burn-in}$, when the chain is still in the so-called $\\textbf{thermalization}$ phase.\n",
    "\n",
    "In order to transit from the value $x_{n}$ of the chain to the value $x_{n + 1}$, we require a $\\textbf{proposal distribution}$ $q$ defined on space $\\chi$. If $q$ is positive everywhere, then the Metropolis-Hastings algorithm preserves $\\tilde{f}$ as the stationary distribution to which the chain is progressively converging. \n",
    "\n",
    "In the $\\textbf{random walk Metropolis-Hastings}$, the proposal distribution consists in a local exploration of the neighborhood of the current value $x_n$ of the\n",
    "Markov chain. That is, the proposed value $y_n$ is simulated as:\n",
    "\n",
    "$$\n",
    "y_n = x_n + \\epsilon_n \\ ,\n",
    "$$\n",
    "\n",
    "where $\\epsilon_n$ is a random perturbation with distribution $g$. As proposal distribution $g$, we focus on a discrete truncated normal distribution centered on $x_n$. A few relevant definitions are discussed next.\n",
    "\n",
    "Finally, since $x_n$ depends on the previous element along the Markov chain, this induces a non-zero correlation between $x_n$ and $x_{n+d}$. The correlation between $x_n$ and $x_{n+d}$ is defined as the $\\textbf{autocorrelation}$ at lag $d$. For a Markov chain that converges to a stationary distribution, the autocorrelation should indeed decrease as the lag increases. The definition of the autocorrelation function between the chain elements $x_n$ and $x_{n+d}$ is defined as the expected value $\\mathbb{E} \\left(x_n x_{n+d} \\right) $.\n",
    "\n",
    "### Truncated normal distribution\n",
    "\n",
    "The probability density function of a normal distribution with mean $0$ and standard deviation $\\sigma$ is defined as:  \n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{-\\frac{x^2}{2 \\sigma^2}} \\ ,\n",
    "$$\n",
    "\n",
    "where $x \\in \\mathbb{R}$. The probability density function of a normal distribution with mean $\\mu$ is simply given by $\\mathcal{N}(x - \\mu, \\sigma)$ .\n",
    "\n",
    "\n",
    "In the discrete (integer) case, we can define the probability density function of a normal distribution with mean $0$ and standard deviation $\\sigma$ as:\n",
    "\n",
    "$$\n",
    "\\mathcal{N}_{d}(n, \\sigma) = \\Phi ( n + 0.5, \\sigma ) - \\Phi (n - 0.5, \\sigma ) \\ ,\n",
    "$$\n",
    "\n",
    "where $n \\in \\mathbb{N}$ and $\\Phi ( x, \\sigma ) $ is the cumulative distribution function of a normal distribution with mean $0$ and standard deviation $\\sigma$, defined as:\n",
    "\n",
    "$$\n",
    "\\Phi (x , \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\int_{- \\infty}^{x} e^{-\\frac{t^2}{2 \\sigma^2}} dt \\ .\n",
    "$$\n",
    "\n",
    "For convenience, let's also define:\n",
    "\n",
    "$$\n",
    "\\Phi (a, b; \\sigma) = \\Phi (b, \\sigma) - \\Phi (a, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\int_{a}^{b} e^{-\\frac{t^2}{2 \\sigma^2}} dt \\ .\n",
    "$$\n",
    "\n",
    "The cumulative distribution function of a discrete (integer) gaussian is written as:\n",
    "\n",
    "$$\n",
    "\\Phi_{d} (n_1, n_2; \\sigma) = \\mathcal{N}_{d}(n_1, \\sigma) + \\mathcal{N}_{d}(n_1 + 1, \\sigma) + \\dots + \\mathcal{N}_{d}(n_2, \\sigma) \\ .\n",
    "$$\n",
    "\n",
    "With the above definitions, we can define the probability density function of a truncated discrete (integer) normal distribution between $n_1$ and $n_2$ as:\n",
    "\n",
    "$$\n",
    "\\mathcal{N_{d, t}}(n, n_1, n_2; \\sigma) = \\frac{\\mathcal{N_{d}}(n, \\sigma)}{\\Phi_{d} (n_1, n_2; \\sigma)} \\ .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90ce09-4529-4090-ba15-c9c8a373d335",
   "metadata": {},
   "source": [
    "# Single vertex random walk\n",
    "\n",
    "Here I build a version of random walk over LQG intertwiners of a single 4-simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee225a2-dfd7-420d-80f3-e48894b55a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Function}:\n",
       " format_current_cell (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JupyterFormatter\n",
    "enable_autoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0451367-2990-4903-8d09-6c2b9fd43d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "\n",
    "@everywhere begin\n",
    "    using HalfIntegers, JLD2, ElasticArrays, Distributions, Random, StatsBase\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8610a317-3463-4c06-99fd-97582d2dc045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5 processes and 4 workers\n"
     ]
    }
   ],
   "source": [
    "if (nprocs() == 1)\n",
    "    addprocs(4)\n",
    "end\n",
    "println(\"there are $(nprocs()) processes and $(nworkers()) workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5b0b47-097b-4bc6-88ed-a1ec0b4428c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function random_walk_function(\n",
    "    j::Float64,\n",
    "    D::Int64,\n",
    "    d::Int64,\n",
    "    A::Array{Float64,5},\n",
    "    N::Int64,\n",
    "    b::Int64,\n",
    "    σ::Float64,\n",
    "    draws_folder::String,\n",
    "    chain_id::Int64,\n",
    "    model::String,\n",
    "    verbosity::Int64,\n",
    ")\n",
    "\n",
    "    draws = ElasticArray{Int64}(undef, 6, 0)     # some allocations    \n",
    "    ampls = ElasticArray{Float64}(undef, 0)\n",
    "\n",
    "    Truncated_Coefficients = zeros(Float64, D)    # some allocations   \n",
    "    Normal_distribution = Normal(0, σ)\n",
    "\n",
    "    for i = 0:d\n",
    "        r = 0.0\n",
    "        for n = (-i):1:(d-i)\n",
    "            r += (cdf(Normal_distribution, n + 0.5) - cdf(Normal_distribution, n - 0.5))\n",
    "        end\n",
    "        Truncated_Coefficients[i+1] = r\n",
    "    end\n",
    "\n",
    "    if (myid() == 1)\n",
    "        if (verbosity > 1)\n",
    "            println(\"Truncated coefficients for j=$(j) are $(Truncated_Coefficients)\\n\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    #Initial draw and gaussian \n",
    "    draw = Array{Int64}(undef, 6)           # some allocations --- # 1 final slot for molteplicity\n",
    "    gaussian_draw = Array{Int64}(undef, 5)  # some allocations \n",
    "\n",
    "    amp = 0.0\n",
    "    while (amp == 0)\n",
    "        for i = 1:5\n",
    "            draw[i] = rand((1:D))     # some allocations        \n",
    "        end\n",
    "        amp = A[draw[1], draw[2], draw[3], draw[4], draw[5]]\n",
    "    end\n",
    "\n",
    "    draw[6] = 1 # Initial molteplicity      \n",
    "\n",
    "    if (myid() == 1)\n",
    "        if (verbosity > 1)\n",
    "            println(\"Initial draw is $(draw[1:5]) with amp $(amp)\\n\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    #Proposed draw  \n",
    "    prop_draw = Array{Int64}(undef, 5)      # some allocations\n",
    "\n",
    "    acceptance_ratio = 0\n",
    "    molteplicity = 1                              # initial molteplicity counter\n",
    "    draw_float_sample = Array{Float64}(undef, 1)   # some allocations --- Distribution pkg does not allow it to be scalar without allocating memory     \n",
    "\n",
    "    RW_monitor = true  # to test if the RW actually moved\n",
    "\n",
    "    for n = 1:1:N\n",
    "\n",
    "        RW_monitor = true\n",
    "\n",
    "        # Sampling proposed draw   \n",
    "        Cx = Cx_prop = 1.0\n",
    "        for i = 1:1:5\n",
    "            while true\n",
    "                rand!(Normal_distribution, draw_float_sample)\n",
    "                @inbounds gaussian_draw[i] = round(Int64, draw_float_sample[1])\n",
    "                @inbounds prop_draw[i] = draw[i] + gaussian_draw[i]\n",
    "                @inbounds !(1 <= prop_draw[i] && prop_draw[i] <= (D)) || break\n",
    "            end\n",
    "            if (gaussian_draw[i] != 0)\n",
    "                RW_monitor = false\n",
    "            end\n",
    "            @inbounds Cx *= Truncated_Coefficients[draw[i]]\n",
    "            @inbounds Cx_prop *= Truncated_Coefficients[prop_draw[i]]\n",
    "        end\n",
    "\n",
    "        if (RW_monitor == true)\n",
    "\n",
    "            if (myid() == 1)\n",
    "                if (verbosity > 1)\n",
    "                    println(\n",
    "                        \"Iteration $(n)---------------------------------------------------------------\\n\",\n",
    "                    )\n",
    "                    println(\n",
    "                        \"The prop_draw below:\\n$(prop_draw[1:5])\\nturns out to be equal to the current draw:\\n$(draw[1:5])\\nso that the molteplicity of the current draw is raised to $(molteplicity + 1)\\n\",\n",
    "                    )\n",
    "                end\n",
    "            end\n",
    "\n",
    "            acceptance_ratio += 1\n",
    "            molteplicity += 1\n",
    "            continue\n",
    "\n",
    "        else\n",
    "\n",
    "            if (myid() == 1)\n",
    "                if (verbosity > 1)\n",
    "                    println(\n",
    "                        \"Iteration $(n)---------------------------------------------------------------\\n\",\n",
    "                    )\n",
    "                    println(\n",
    "                        \"draw is:\\n$(draw[1:5])\\nprop_draw is:\\n$(prop_draw[1:5])\\namp is $(amp)\\n\",\n",
    "                    )\n",
    "                end\n",
    "            end\n",
    "\n",
    "\n",
    "            Prop_amp =\n",
    "                A[prop_draw[1], prop_draw[2], prop_draw[3], prop_draw[4], prop_draw[5]]\n",
    "\n",
    "            p = min(1.0, (((Prop_amp^2) / (amp^2))) * (Cx / Cx_prop))\n",
    "\n",
    "            if (isnan(p))\n",
    "                error(\n",
    "                    \"got NaN while computing densities ratio: prop_draw = $(prop_draw), amp = $(amp)\",\n",
    "                )\n",
    "            end\n",
    "\n",
    "            r = rand()\n",
    "\n",
    "            if (r < p)\n",
    "\n",
    "                if (myid() == 1)\n",
    "                    if (verbosity > 1)\n",
    "                        println(\n",
    "                            \"prop_draw $(prop_draw) was accepted, since p=$(p) and r=$(r)\\n\",\n",
    "                        )\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                if (n > b)\n",
    "                    # TODO avoid resizing at every iteration (pre-allocating assuming >~ 30% accept. rate and re-allocated only at the end) \n",
    "                    # and eventually replace matrices with 1-d arrays (more efficient?)\n",
    "                    resize!(draws, 6, size(draws)[2] + 1)     # some allocations\n",
    "                    resize!(ampls, size(ampls)[1] + 1)         # some allocations\n",
    "                    draw[6] = molteplicity\n",
    "                    draws[:, end] = draw[:]\n",
    "                    ampls[end] = amp\n",
    "\n",
    "                    if (myid() == 1)\n",
    "                        if (verbosity > 1)\n",
    "                            println(\n",
    "                                \"The old draw $(draw[1:5]) has been stored with molteplicity $(draw[6])\\nthe corresponding amplitude $(amp) has been stored as well\",\n",
    "                            )\n",
    "                        end\n",
    "                    end\n",
    "\n",
    "                end\n",
    "\n",
    "                molteplicity = 1\n",
    "\n",
    "                for i = 1:5\n",
    "                    draw[i] = prop_draw[i]\n",
    "                end\n",
    "\n",
    "                amp = Prop_amp\n",
    "                acceptance_ratio += 1\n",
    "\n",
    "                if (myid() == 1)\n",
    "                    if (verbosity > 1)\n",
    "                        println(\"Now the new draw is $(draw[1:5])\\nthe new amp is $(amp)\\n\")\n",
    "                    end\n",
    "                end\n",
    "            else\n",
    "                molteplicity += 1\n",
    "                if (myid() == 1)\n",
    "                    if (verbosity > 1)\n",
    "                        println(\n",
    "                            \"prop_draw $(prop_draw) was rejected, since p=$(p) and r=$(r)\\nThe current draw $(draw[1:5]) remains the same and its molteplicity is $(molteplicity)\\namp remains $(amp)\\n\",\n",
    "                        )\n",
    "                    end\n",
    "                end\n",
    "            end # if condition  (r<p)\n",
    "\n",
    "        end # if condition  RW_monitor == true  \n",
    "\n",
    "        # final storage  \n",
    "        if (n == N)\n",
    "            resize!(draws, 6, size(draws)[2] + 1)     # some allocations \n",
    "            resize!(ampls, size(ampls)[1] + 1)         # some allocations \n",
    "            draw[6] = molteplicity\n",
    "            draws[:, end] .= draw[:]\n",
    "            ampls[end] = amp\n",
    "            if (myid() == 1)\n",
    "                if (verbosity > 1)\n",
    "                    println(\n",
    "                        \"The last draw $(draw[1:5]) has been stored with molteplicity $(draw[6])\\n\",\n",
    "                    )\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "    end # n cycle      \n",
    "\n",
    "    #This is such that draws has structure: [N,6], so the operators will be computed faster  \n",
    "    draws = transpose(draws)  # some allocations  \n",
    "\n",
    "    if (chain_id == 1)\n",
    "        println(\n",
    "            \"Done! $(acceptance_ratio*100/N)% of proposed draws have been accepted in master chain\",\n",
    "        )\n",
    "    end\n",
    "\n",
    "    draws_number = size(draws)[1]\n",
    "\n",
    "    if (chain_id == 1)\n",
    "        if (verbosity > 0)\n",
    "            println(\"$(draws_number) draws stored in master chain\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @save \"$(draws_folder)/$(model)_j_$(j)_draws_chain=$(chain_id).jld2\" draws    # some allocations \n",
    "    @save \"$(draws_folder)/$(model)_j_$(j)_ampls_chain=$(chain_id).jld2\" ampls    # some allocations \n",
    "\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
