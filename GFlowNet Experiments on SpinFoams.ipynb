{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2008af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.trainer import train_gfn\n",
    "\n",
    "spin_js = [0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]\n",
    "single_vertex_params = [{\n",
    "    \"spin_j\" : j,\n",
    "    \"sf_model\" : \"single_vertex_model\",\n",
    "    \"main_layer_hidden_nodes\" : (\n",
    "        int(2*j+1)*5, max( int(2*j+1)*5 // 2, 10), 6\n",
    "    ),\n",
    "    \"branch1_hidden_nodes\" : (),\n",
    "    \"branch2_hidden_nodes\" : (),\n",
    "    \"activation\" : \"swish\",\n",
    "    \"exploration_rate\" : 0.5, #try 0\n",
    "    \"training_fraction_from_back_traj\" : 0.0,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \"batch_size\" : int(1e3),\n",
    "    \"n_iterations\" : int(1e4),\n",
    "    \"evaluation_batch_size\" : int(1e6),\n",
    "    \"generate_samples_every_m_training_samples\" : int(1e6),\n",
    "} for j in spin_js]\n",
    "\n",
    "# star_params = [{\n",
    "#     \"spin_j\" : j,\n",
    "#     \"sf_model\" : \"star_model\",\n",
    "#     \"main_layer_hidden_nodes\" : (\n",
    "#         int(2*j+1)*20, max( int(2*j+1)*20 // 2, 40), max( int(2*j+1)*20 // 4, 30), 21\n",
    "#     ),\n",
    "#     \"branch1_hidden_nodes\" : (),\n",
    "#     \"branch2_hidden_nodes\" : (),\n",
    "#     \"activation\" : \"swish\",\n",
    "#     \"exploration_rate\" : 0.5,\n",
    "#     \"training_fraction_from_back_traj\" : 0.5,\n",
    "#     \"learning_rate\" : 0.001,\n",
    "#     \"batch_size\" : int(1e3),\n",
    "#     \"n_iterations\" : int(1e4),\n",
    "#     \"evaluation_batch_size\" : int(5e4),\n",
    "#     \"generate_samples_every_m_training_samples\" : int(1e6),\n",
    "# } for j in spin_js]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8715f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for params in single_vertex_params:\n",
    "# for params in star_params:\n",
    "    losses.append(train_gfn(**params, model_save_dir=\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b664d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intertwiner 5</th>\n",
       "      <th>intertwiner 4</th>\n",
       "      <th>intertwiner 3</th>\n",
       "      <th>intertwiner 2</th>\n",
       "      <th>intertwiner 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intertwiner 5  intertwiner 4  intertwiner 3  intertwiner 2  intertwiner 1\n",
       "0              1              0              0              1              0\n",
       "1              0              1              0              0              0\n",
       "2              0              1              0              0              1\n",
       "3              1              1              1              1              1\n",
       "4              1              1              1              1              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_feather(\"./generated_samples/epoch_1000_after_learn_from_1000000_train_samples.feather\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e88cbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from core.trainer import train_gfn\n",
    "\n",
    "params = {\n",
    "    \"spin_j\" : 3.5,\n",
    "    \"sf_model\" : \"single_vertex_model\",\n",
    "    \"main_layer_hidden_nodes\" : (\n",
    "#         128, 128, 64, 64, 32, 32, 16, 16, 8, 8\n",
    "        128, 32, 32, 8\n",
    "    ),\n",
    "    \"branch1_hidden_nodes\" : (),\n",
    "    \"branch2_hidden_nodes\" : (),\n",
    "    \"activation\" : \"swish\",\n",
    "    \"exploration_rate\" : 0.5,\n",
    "    \"training_fraction_from_back_traj\" : 0.5,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \"batch_size\" : int(1e3),\n",
    "    \"n_iterations\" : int(1e4),\n",
    "    \"evaluation_batch_size\" : int(5e4),\n",
    "    \"generate_samples_every_m_training_samples\" : int(1e6),\n",
    "}\n",
    "\n",
    "ave_losses = train_gfn(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 1.9609801666379112\n",
    "Nth iteration: 2000 Trained on K samples: 2000000 Average Loss: 1.065302608731616\n",
    "Nth iteration: 3000 Trained on K samples: 3000000 Average Loss: 0.59914980090523229\n",
    "Nth iteration: 4000 Trained on K samples: 4000000 Average Loss: 0.38473474757335896\n",
    "Nth iteration: 5000 Trained on K samples: 5000000 Average Loss: 0.35055703172378194\n",
    "Nth iteration: 6000 Trained on K samples: 6000000 Average Loss: 0.32772723318299496\n",
    "Nth iteration: 7000 Trained on K samples: 7000000 Average Loss: 0.29690569581730686\n",
    "Nth iteration: 8000 Trained on K samples: 8000000 Average Loss: 0.39323040688549454\n",
    "Nth iteration: 9000 Trained on K samples: 9000000 Average Loss: 0.28258110530944874\n",
    "Nth iteration: 10000 Trained on K samples: 10000000 Average Loss: 0.25508918216647825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961da3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 1.3386958754352229\n",
    "Nth iteration: 2000 Trained on K samples: 2000000 Average Loss: 1.0995962435696534\n",
    "Nth iteration: 3000 Trained on K samples: 3000000 Average Loss: 0.85274413082630662\n",
    "Nth iteration: 4000 Trained on K samples: 4000000 Average Loss: 0.45730040409348371\n",
    "Nth iteration: 5000 Trained on K samples: 5000000 Average Loss: 0.60429376325367323\n",
    "Nth iteration: 6000 Trained on K samples: 6000000 Average Loss: 0.382636286629316\n",
    "Nth iteration: 7000 Trained on K samples: 7000000 Average Loss: 0.42668693697825882\n",
    "Nth iteration: 8000 Trained on K samples: 8000000 Average Loss: 0.39781253586940124\n",
    "Nth iteration: 9000 Trained on K samples: 9000000 Average Loss: 0.29250289648957822\n",
    "Nth iteration: 10000 Trained on K samples: 10000000 Average Loss: 0.245781074454583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621d856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12315da",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
    "for j, l in zip(spin_js, losses):\n",
    "    ax.plot(l, label=j)\n",
    "ax.legend()\n",
    "# ax.set_ylim((0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8cb132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713614cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "spins = [0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6]\n",
    "# nodes = {\n",
    "#     0.5: (15, 10),\n",
    "#     1: (20, 10),\n",
    "#     1.5: (25, 10),\n",
    "#     2: (30, 15),\n",
    "#     2.5: (35, 15),\n",
    "#     3: (40, 15),\n",
    "#     3.5: (45, 20),\n",
    "#     4: (50, 20),\n",
    "#     4.5: ()\n",
    "# }\n",
    "\n",
    "enc_dim = [int(2*j+1)*20 for j in spins]\n",
    "enc_dim\n",
    "\n",
    "# train_gfn(\n",
    "#     spin_j=3.5, \n",
    "#     sf_model=\"single_vertex_model\",\n",
    "#     main_layer_hidden_nodes=(30, 20), \n",
    "#     branch1_hidden_nodes=(), \n",
    "#     branch2_hidden_nodes=(),\n",
    "#     activation=\"swish\",\n",
    "#     exploration_rate=0.5,\n",
    "#     training_fraction_from_back_traj=0.0,\n",
    "#     learning_rate=0.0005,\n",
    "#     batch_size=int(1e3),\n",
    "#     n_iterations=int(1e4),\n",
    "#     evaluation_batch_size=int(1e6),\n",
    "#     generate_samples_every_m_training_samples=int(1e6),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af79020",
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(2*j+1)*20//4 for j in spins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df256afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0204407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80bdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4770afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60938cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a7647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd38b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75210e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from core.runner import Runner\n",
    "from core.environment import SingleVertexSpinFoam, StarModelSpinFoam\n",
    "\n",
    "def train_gfn(\n",
    "    spin_j=3.5, \n",
    "    sf_model=\"single_vertex_model\",\n",
    "    main_layer_hidden_nodes=(30, 20), \n",
    "    branch1_hidden_nodes=(), \n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    training_fraction_from_back_traj=0.0,\n",
    "    learning_rate=0.0005,\n",
    "    batch_size=int(1e3),\n",
    "    n_iterations=int(1e4),\n",
    "    evaluation_batch_size=int(1e6),\n",
    "    generate_samples_every_m_training_samples=int(1e6),\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a GFlowNet agent to sample grid coordinates with probabilities proportional \n",
    "    to a target reward distribution. The SpinFoam model defines the grid environment \n",
    "    which the agent interacts with. The grid coordinates then correspond to an ordered \n",
    "    set of boundary intertwiners while the square of the SpinFoam amplitudes define the \n",
    "    reward for each grid coordinate. This results in grid coordinates with higher rewards\n",
    "    being sampled more frequently so that the corresponding boundary intertwiners can be\n",
    "    used for the calculation of observables downstream.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    spin_j: (float)\n",
    "                - Half-integer boundary spin. All boundary spins are fixed to this value\n",
    "                - Determines the grid length. All sides of the grid have length: \n",
    "                  grid_length = 2*spin_j + 1\n",
    "                \n",
    "    sf_model: (str)\n",
    "                - Name specifying the particular spinfoam model. Currently, can only be\n",
    "                  \"single_vertex_model\" or \"star_model\". Custom SpinFoam classes can also\n",
    "                  be implemented. \n",
    "                - Determines the number of boundary intertwiners which in turn determines the\n",
    "                  dimensionality of the grid. \n",
    "                - E.g. \"single_vertex_model\" -> 5-dimensional grid: grid_dim = 5, \n",
    "                       \"star_model\" -> 20-dimensional grid: grid_dim = 20\n",
    "                  \n",
    "    main_layer_hidden_nodes: (tuple)\n",
    "                - Tuple of integers defining the number of hidden nodes per layer after the \n",
    "                  input layer in the main neural network branch. This main branch splits into\n",
    "                  two branches corresponding to backward and forward action probabilities. \n",
    "                  So, the last layer of the main branch connects to both the first layers of\n",
    "                  the backward-action and forward-action branches.\n",
    "                - Input layer contains grid_length*grid_dim nodes because of the one-hot \n",
    "                  encoding of each grid coordinate\n",
    "                - E.g. (128, 64, 32) -> 3 layers after the input layer in the main branch: \n",
    "                                        128 nodes for the first one, 64 for the next, and 32\n",
    "                                        for the last\n",
    "                                        \n",
    "                Ex: spin=3.5, sf_model=\"single_vertex_model\"\n",
    "                 -> grid_length=8, grid_dim=5\n",
    "                 -> input layer = 8*5 = 40\n",
    "                 -> output layer = 5, 6\n",
    "                 -> main_layer_hidden_nodes = (64, 40, 10), (30, 15)\n",
    "                 \n",
    "                 spin=3.5, sf_model=\"star_model\"\n",
    "                 -> input layer = 8*20 = 160\n",
    "                 -> output layer = 20, 21\n",
    "                 -> main_layer_hidden_nodes = (120, 60, 30), (200, 150, 100, 50), (120, 30)\n",
    "                \n",
    "                                        \n",
    "    branch1_hidden_nodes: (tuple)\n",
    "                - Tuple of integers (or empty tuple) defining the number of hidden nodes per \n",
    "                  layer in the backward-action branch before the output layer\n",
    "                - Output layer for this branch contains grid_dim nodes\n",
    "                - E.g. (16, 8) -> 2 layers before the output layer:\n",
    "                                  16 for the first one, then 8 for the next\n",
    "                       () -> there is only the output layer in this branch\n",
    "                       \n",
    "    branch2_hidden_nodes: (tuple)\n",
    "                - Tuple of integers (or empty tuple) defining the number of hidden nodes per \n",
    "                  layer in the forward-action branch before the output layer\n",
    "                - Output layer for this branch contains grid_dim+1 nodes\n",
    "                - E.g. (16, 8) -> 2 layers before the output layer:\n",
    "                                  16 for the first one, then 8 for the next\n",
    "                       () -> there is only the output layer in this branch\n",
    "                       \n",
    "    activation: (str)\n",
    "                - Name of the nonlinear functions used for each layer other than the output layers\n",
    "                - E.g.: elu, exponential, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softmax, \n",
    "                        softplus, softsign, swish, tanh\n",
    "                - tanh, swish, relu\n",
    "                        \n",
    "    exploration_rate: (float)\n",
    "                - Number from 0 to 1 representing the amount of random noise added to the forward \n",
    "                  actions. More noise encourages the agent to explore the grid environment further\n",
    "                - Given by: New_action_proabilities = (\n",
    "                                exploration_rate*noise_action_probabilities + \n",
    "                                (1 - exploration_rate)*current_action_probabilities\n",
    "                            )\n",
    "                - I.e.: exploration_rate = 0 -> no noise added\n",
    "                        exploration_rate = 1 -> actions are just from random noise\n",
    "                        \n",
    "                        =0.5\n",
    "\n",
    "                        \n",
    "    training_fraction_from_back_traj: (float)\n",
    "                - Number from 0 to 1 representing the fraction of the training set which is \n",
    "                  generated from backward trajectories. The rest is generated from forward trajectories.\n",
    "                - I.e.: n_batch_backwards = training_fraction_from_back_traj*batch_size\n",
    "                        n_batch_forwards = (1 - training_fraction_from_back_traj)*batch_size\n",
    "                        \n",
    "                    \"single_vertex\" -> 0.0, \"star_model\" -> 0.5\n",
    "                        \n",
    "    learning_rate: (float)\n",
    "                - Represents the amount of the gradient used by the optimizer to update the neural \n",
    "                  network parameters per training iteration \n",
    "                  \n",
    "    batch_size: (int)\n",
    "                - Number of trajectories generated per training iteration. These trajectories form\n",
    "                  the training set that the agent learns from. \n",
    "                  \n",
    "                  = 1000\n",
    "                  \n",
    "    n_iterations: (int)\n",
    "                - Number of training iterations for the agent\n",
    "                \n",
    "                = 10000\n",
    "                \n",
    "    evaluation_batch_size: (int)\n",
    "                - Number of grid coordinates that the agent generates and stores for later evaluation\n",
    "                \n",
    "                = 10000\n",
    "                \n",
    "    generate_samples_every_m_training_samples: (int)\n",
    "                - Number of trajectories generated during training before the agent samples new \n",
    "                  grid coordinates and stores them\n",
    "                  \n",
    "                = batch_mcmc\n",
    "    \"\"\"\n",
    "    if sf_model == \"single_vertex_model\":\n",
    "        spinfoam_model = SingleVertexSpinFoam(spin_j=spin_j)\n",
    "    elif sf_model == \"star_model\":\n",
    "        spinfoam_model = StarModelSpinFoam(spin_j=spin_j)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Spinfoam model not yet implemented. \"\n",
    "            \"Custom Spinfoam class can be made.\"\n",
    "        )\n",
    "        \n",
    "    training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "    directory_for_generated_samples = (\n",
    "        f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    "    )\n",
    "    \n",
    "    runner = Runner(\n",
    "        spinfoam_model=spinfoam_model,\n",
    "        main_layer_hidden_nodes=main_layer_hidden_nodes,\n",
    "        branch1_hidden_nodes=branch1_hidden_nodes,\n",
    "        branch2_hidden_nodes=branch2_hidden_nodes,\n",
    "        activation=activation,\n",
    "        exploration_rate=exploration_rate,\n",
    "        training_fraction_from_back_traj=training_fraction_from_back_traj,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    \n",
    "    ave_losses = runner.train_agent(\n",
    "        batch_size, n_iterations, \n",
    "        evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "        directory_for_generated_samples\n",
    "    )\n",
    "    \n",
    "    return ave_losses\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e01feef7",
   "metadata": {},
   "source": [
    "# Single Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_losses = train_gfn(\n",
    "    spin_j=3.5, \n",
    "    sf_model=\"single_vertex_model\",\n",
    "    main_layer_hidden_nodes=(30, 20), \n",
    "    branch1_hidden_nodes=(), \n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    training_fraction_from_back_traj=0.0,\n",
    "    learning_rate=0.0005,\n",
    "    batch_size=int(1e3),\n",
    "    n_iterations=int(1e4),\n",
    "    evaluation_batch_size=int(1e6),\n",
    "    generate_samples_every_m_training_samples=int(1e6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b86285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ave_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "095adb11",
   "metadata": {},
   "source": [
    "# Star Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_losses = train_gfn(\n",
    "    spin_j=3.5, \n",
    "    sf_model=\"star_model\",\n",
    "    main_layer_hidden_nodes=(128, 64, 64), \n",
    "    branch1_hidden_nodes=(), \n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    training_fraction_from_back_traj=0.5,\n",
    "    learning_rate=0.0005,\n",
    "    batch_size=int(1e3),\n",
    "    n_iterations=int(1e4),\n",
    "    evaluation_batch_size=int(1e6),\n",
    "    generate_samples_every_m_training_samples=int(1e6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56667b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ave_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718e12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2ecb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd9f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1a611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ebd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc2010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a511d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5023e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34868e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282219b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import SingleVertexSpinFoam\n",
    "\n",
    "spin_j = 3.5\n",
    "sf_model = \"single_vertex_model\"\n",
    "\n",
    "runner = Runner(\n",
    "    spinfoam_model=SingleVertexSpinFoam(spin_j=spin_j),\n",
    "    main_layer_hidden_nodes=(30, 20),\n",
    "    branch1_hidden_nodes=(),\n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    training_fraction_from_back_traj=0.0,\n",
    "    learning_rate=0.0005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "directory_for_generated_samples = (\n",
    "    f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    ")\n",
    "\n",
    "batch_size = int(1e3)\n",
    "n_iterations = int(1e3)\n",
    "# n_iterations = int(300)\n",
    "evaluation_batch_size = int(10)\n",
    "generate_samples_every_m_training_samples = int(2e5)\n",
    "\n",
    "ave_losses = runner.train_agent(\n",
    "    batch_size, n_iterations, \n",
    "    evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "    directory_for_generated_samples\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0456a3e",
   "metadata": {},
   "source": [
    "# Star Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import StarModelSpinFoam\n",
    "\n",
    "spin_j = 3.5\n",
    "sf_model = \"star_model\"\n",
    "\n",
    "runner = Runner(\n",
    "    spinfoam_model=StarModelSpinFoam(spin_j=spin_j),\n",
    "    main_layer_hidden_nodes=(128, 64, 64),\n",
    "    branch1_hidden_nodes=(),\n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    training_fraction_from_back_traj=0.1,\n",
    "    learning_rate=0.0005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ae4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "directory_for_generated_samples = (\n",
    "    f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    ")\n",
    "\n",
    "batch_size = int(1e3)\n",
    "n_iterations = int(1e3)\n",
    "# n_iterations = int(300)\n",
    "evaluation_batch_size = int(10)\n",
    "generate_samples_every_m_training_samples = int(2e5)\n",
    "\n",
    "ave_losses = runner.train_agent(\n",
    "    batch_size, n_iterations, \n",
    "    evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "    directory_for_generated_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826b6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae83d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ccee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01317250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c22ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc000fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa64577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94650954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f287d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed84e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef4d8f89",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "\n",
    "# Previous tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3dd036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e44c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486ca0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8accb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf45cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4102e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf8602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd60c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import SingleVertexSpinFoam\n",
    "\n",
    "spin_j = 3.5\n",
    "sf_model = \"single_vertex_model\"\n",
    "\n",
    "runner = Runner(\n",
    "    spinfoam_model=SingleVertexSpinFoam(),\n",
    "    spin_j=spin_j,\n",
    "    main_layer_hidden_nodes=(30, 20),\n",
    "    branch1_hidden_nodes=(),\n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    learning_rate=0.0005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057e953",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "directory_for_generated_samples = (\n",
    "    f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = int(1e3)\n",
    "n_iterations = int(1e3)\n",
    "# n_iterations = int(300)\n",
    "fraction_of_training_from_back_trajectories = 0.0\n",
    "evaluation_batch_size = int(2e5)\n",
    "generate_samples_every_m_training_samples = int(2e5)\n",
    "\n",
    "ave_losses = runner.train_agent(\n",
    "    batch_size, n_iterations, fraction_of_training_from_back_trajectories, \n",
    "    evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "    directory_for_generated_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.999 Max\n",
    "\n",
    "\n",
    "Nth iteration: 1 Average Loss: 10.313235918730944\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 3.8410917472658523\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 3.2507308831058417\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 4.3149855892960058\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 3.5061072391776023\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 2.4787907542318872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec615d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.99 Max\n",
    "\n",
    "Nth iteration: 1 Average Loss: 13.300160685018087\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 5.0689388321024333\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 3.6152086536530477\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 3.0158918708159232\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 2.2089659154210057\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 1.4632014533468054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc93dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 15.041544509167547\n",
    "            \n",
    "Nth iteration: 1 Average Loss: 27.833997273130787\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 14.439725408179275\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 8.581400663157444\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 4.7001221032761746\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 3.9371769914849057\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 2.5361100055773012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Max\n",
    "\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 3.6238780132468866\n",
    "\n",
    "Nth iteration: 1 Average Loss: 10.613150147572496\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 3.5966320343431581\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 4.494772864296265\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 4.1429286237455232\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 3.9257716045337037\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 3.7467994673681444\n",
    "            \n",
    "Nth iteration: 1 Average Loss: 10.208967923761881\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 4.71511010701389\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 5.5712986666670261\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 4.24535714700103\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 3.7134989553479949\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 3.1275138985696822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aeb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean\n",
    "\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 24.56604181036295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "single_vertex_amplitudes = runner.env.single_vertex_amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_abs = tf.math.reduce_mean(tf.math.abs(single_vertex_amplitudes))\n",
    "ave_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*tf.math.log(ave_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11609a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "-22, -12, -14, -19\n",
    "-49, -52, -61, -84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc035a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0f320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbb940",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_scale = tf.math.reduce_sum(tf.math.square(single_vertex_amplitudes))\n",
    "sq_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf180a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_log_z = tf.math.log(sq_scale)\n",
    "prev_log_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a443665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_abs = tf.math.reduce_max(tf.math.abs(single_vertex_amplitudes))\n",
    "max_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655318d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*tf.math.log(max_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea55ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sq = tf.math.reduce_max(tf.math.square(single_vertex_amplitudes))\n",
    "max_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.log(max_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_abs = tf.math.reduce_min(tf.math.abs(single_vertex_amplitudes))\n",
    "min_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b67e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*tf.math.log(min_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "-52.23322188306788*0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d221e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab02022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import SingleVertexSpinFoam\n",
    "\n",
    "spin_j = 6.0\n",
    "sf_model = \"single_vertex_model\"\n",
    "\n",
    "runner = Runner(\n",
    "    spinfoam_model=SingleVertexSpinFoam(),\n",
    "    spin_j=spin_j,\n",
    "    main_layer_hidden_nodes=(50, 20),\n",
    "    branch1_hidden_nodes=(),\n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    learning_rate=0.0005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681cfcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "directory_for_generated_samples = (\n",
    "    f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = int(1e3)\n",
    "n_iterations = int(1e3)\n",
    "# n_iterations = int(300)\n",
    "fraction_of_training_from_back_trajectories = 0.0\n",
    "evaluation_batch_size = int(10)\n",
    "generate_samples_every_m_training_samples = int(2e5)\n",
    "\n",
    "ave_losses = runner.train_agent(\n",
    "    batch_size, n_iterations, fraction_of_training_from_back_trajectories, \n",
    "    evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "    directory_for_generated_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0923a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Max\n",
    "\n",
    "Nth iteration: 1 Average Loss: 20.836390882130726\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 2.0459407847597513\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 1.4585196694603741\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 0.97864002385061055\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 0.52738381254082678\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 0.841442386344152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.99 Max\n",
    "\n",
    "Nth iteration: 1 Average Loss: 25.94910689433053\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 3.7002476080396289\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 1.6780714611113932\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 0.868219155780009\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 1.2639663788832127\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 0.96857257687373355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ada9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig\n",
    "\n",
    "Nth iteration: 1 Average Loss: 46.807858204553668\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 11.916711202519357\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 9.34522011892435\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 8.6954130018196949\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 7.1471832212631705\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 6.4898161948653925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bbe33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e415c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13fb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed1520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import SingleVertexSpinFoam\n",
    "\n",
    "spin_j = 3.5\n",
    "sf_model = \"single_vertex_model\"\n",
    "\n",
    "runner = Runner(\n",
    "    spinfoam_model=SingleVertexSpinFoam(),\n",
    "    spin_j=spin_j,\n",
    "    main_layer_hidden_nodes=(30, 20),\n",
    "    branch1_hidden_nodes=(),\n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    learning_rate=0.0005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14606d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "directory_for_generated_samples = (\n",
    "    f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = int(1e3)\n",
    "# n_iterations = int(1e3)\n",
    "n_iterations = int(100)\n",
    "fraction_of_training_from_back_trajectories = 0.75\n",
    "evaluation_batch_size = int(10)\n",
    "generate_samples_every_m_training_samples = int(2e5)\n",
    "\n",
    "ave_losses = runner.train_agent(\n",
    "    batch_size, n_iterations, fraction_of_training_from_back_trajectories, \n",
    "    evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "    directory_for_generated_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d6b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "-52.23322188306788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e08644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46233686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5722fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import SingleVertexSpinFoam\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "list_of_ave_losses = []\n",
    "\n",
    "for f in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
    "    spin_j = 6.0\n",
    "    sf_model = \"single_vertex_model\"\n",
    "\n",
    "    runner = Runner(\n",
    "        spinfoam_model=SingleVertexSpinFoam(),\n",
    "        spin_j=spin_j,\n",
    "        main_layer_hidden_nodes=(50, 20),\n",
    "        branch1_hidden_nodes=(),\n",
    "        branch2_hidden_nodes=(),\n",
    "        activation=\"swish\",\n",
    "        exploration_rate=0.5,\n",
    "        learning_rate=0.0005\n",
    "    )\n",
    "    training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "    directory_for_generated_samples = (\n",
    "        f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    batch_size = int(1e3)\n",
    "    n_iterations = int(1e4)\n",
    "    fraction_of_training_from_back_trajectories = f\n",
    "    evaluation_batch_size = int(2e3)\n",
    "    generate_samples_every_m_training_samples = int(2e6)\n",
    "\n",
    "    ave_losses = runner.train_agent(\n",
    "        batch_size, n_iterations, fraction_of_training_from_back_trajectories, \n",
    "        evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "        directory_for_generated_samples\n",
    "    )\n",
    "    list_of_ave_losses.append(ave_losses)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92367df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, f in enumerate([0.0, 0.25, 0.5, 0.75, 1.0]):\n",
    "    plt.plot(list_of_ave_losses[i], label=f)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919fd0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e86797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe098eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, f in enumerate([0.0, 0.25, 0.5, 0.75, 1.0]):\n",
    "    plt.plot(list_of_ave_losses[i], label=f)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_ave_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55b8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea4942ca",
   "metadata": {},
   "source": [
    "# Star Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f8c0e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import StarModelSpinFoam\n",
    "\n",
    "spin_j = 3.5\n",
    "sf_model = \"star_model\"\n",
    "\n",
    "runner = Runner(\n",
    "    spinfoam_model=StarModelSpinFoam(),\n",
    "    spin_j=spin_j,\n",
    "    main_layer_hidden_nodes=(128, 64, 64),\n",
    "    branch1_hidden_nodes=(),\n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    learning_rate=0.0005\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87778a5d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "directory_for_generated_samples = (\n",
    "    f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    ")\n",
    "\n",
    "batch_size = int(1e3)\n",
    "n_iterations = int(1e4)\n",
    "evaluation_batch_size = int(2e5)\n",
    "generate_samples_every_m_training_samples = int(2e5)\n",
    "\n",
    "ave_losses = runner.train_agent(\n",
    "    batch_size, n_iterations, \n",
    "    evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "    directory_for_generated_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f0a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# np.savetxt(\"Only forward trajectories.csv\", ave_losses.numpy(), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7754616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ave_losses.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c52e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcda46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbf422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce095668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import StarModelSpinFoam\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "list_of_ave_losses = []\n",
    "\n",
    "for f in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
    "    spin_j = 3.5\n",
    "    sf_model = \"star_model\"\n",
    "\n",
    "    runner = Runner(\n",
    "        spinfoam_model=StarModelSpinFoam(),\n",
    "        spin_j=spin_j,\n",
    "        main_layer_hidden_nodes=(128, 64, 64),\n",
    "        branch1_hidden_nodes=(),\n",
    "        branch2_hidden_nodes=(),\n",
    "        activation=\"swish\",\n",
    "        exploration_rate=0.5,\n",
    "        learning_rate=0.0005\n",
    "    )\n",
    "    training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "    directory_for_generated_samples = (\n",
    "        f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    batch_size = int(1e3)\n",
    "    n_iterations = int(1e4)\n",
    "    fraction_of_training_from_back_trajectories = f\n",
    "    evaluation_batch_size = int(1e3)\n",
    "    generate_samples_every_m_training_samples = int(1e7)\n",
    "\n",
    "    ave_losses = runner.train_agent(\n",
    "        batch_size, n_iterations, fraction_of_training_from_back_trajectories, \n",
    "        evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "        directory_for_generated_samples\n",
    "    )\n",
    "    list_of_ave_losses.append(ave_losses)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, f in enumerate([0.0, 0.25, 0.5, 0.75, 1.0]):\n",
    "    plt.plot(list_of_ave_losses[i], label=f)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74387621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc43d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2018c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacebf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "from core.environment import StarModelSpinFoam\n",
    "\n",
    "spin_j = 3.5\n",
    "sf_model = \"star_model\"\n",
    "\n",
    "runner = Runner(\n",
    "    spinfoam_model=StarModelSpinFoam(),\n",
    "    spin_j=spin_j,\n",
    "    main_layer_hidden_nodes=(128, 64, 64),\n",
    "    branch1_hidden_nodes=(),\n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    learning_rate=0.0005\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d261e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "training_run_datetime = datetime.now().strftime(\"%B %d, %Y at %H:%M:%S\")\n",
    "directory_for_generated_samples = (\n",
    "    f\"generated_samples_during_training/{sf_model}/j={spin_j}/Training run on {training_run_datetime}\"\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = int(1e3)\n",
    "# n_iterations = int(1e3)\n",
    "n_iterations = int(100)\n",
    "fraction_of_training_from_back_trajectories = 0.75\n",
    "evaluation_batch_size = int(10)\n",
    "generate_samples_every_m_training_samples = int(2e5)\n",
    "\n",
    "ave_losses = runner.train_agent(\n",
    "    batch_size, n_iterations, fraction_of_training_from_back_trajectories, \n",
    "    evaluation_batch_size, generate_samples_every_m_training_samples,\n",
    "    directory_for_generated_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb228f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.99 Max * 6\n",
    "\n",
    "Nth iteration: 1 Average Loss: 256.75957053640968\n",
    "Nth iteration: 200 Trained on K samples: 200000 Average Loss: 27.373910871569272\n",
    "Nth iteration: 400 Trained on K samples: 400000 Average Loss: 20.145873200509026\n",
    "Nth iteration: 600 Trained on K samples: 600000 Average Loss: 13.870413800617818\n",
    "Nth iteration: 800 Trained on K samples: 800000 Average Loss: 9.2659642975085212\n",
    "Nth iteration: 1000 Trained on K samples: 1000000 Average Loss: 8.958290865724539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46efccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "6*2*tf.math.log(tf.reduce_max(tf.math.abs(runner.env.single_vertex_amplitudes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "-313.3993312984073*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3bd7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc05e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "6*2*tf.math.log(tf.reduce_sum(tf.math.abs(runner.env.single_vertex_amplitudes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf4970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b3a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8418e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_max(tf.math.abs(runner.env.single_vertex_amplitudes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.math.abs(runner.env.single_vertex_amplitudes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937eb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840ec63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "421e79ab",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "\n",
    "# Previous tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6cc176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ee44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf7ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6387c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d32023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07273f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07113233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4111a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42bd1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89d424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ff2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb111a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46a19a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T02:59:51.716371Z",
     "start_time": "2023-02-04T02:59:45.296799Z"
    }
   },
   "outputs": [],
   "source": [
    "from core.runner import Runner\n",
    "import tensorflow as tf\n",
    "\n",
    "grid_length = 8\n",
    "\n",
    "runner = Runner(\n",
    "    grid_length=grid_length,\n",
    "    main_layer_hidden_nodes=(40, 30, 20),\n",
    "    branch1_hidden_nodes=(),\n",
    "    branch2_hidden_nodes=(),\n",
    "    activation=\"swish\",\n",
    "    exploration_rate=0.5,\n",
    "    learning_rate=0.001,\n",
    "    environment_mode=\"spinfoam_vertex\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f07f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:33:14.772944Z",
     "start_time": "2023-02-04T02:59:51.789818Z"
    }
   },
   "outputs": [],
   "source": [
    "half_batch_size = tf.constant(500)\n",
    "n_iterations = tf.constant(int(1e4))\n",
    "# n_iterations = tf.constant(500)\n",
    "\n",
    "# evaluate_every_n_iterations = tf.constant(int(1e2))\n",
    "evaluate_every_n_iterations = tf.constant(int(1e3))\n",
    "evaluation_batch_size = tf.constant(int(5e4))\n",
    "# evaluation_batch_sizes = tf.constant([int(1e4), int(5e4), int(1e5), int(5e5)])\n",
    "\n",
    "ave_losses, distr_js_dists, agent_obss = runner.train_agent(\n",
    "    half_batch_size, n_iterations, evaluate_every_n_iterations, evaluation_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420a710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:44:24.584473Z",
     "start_time": "2023-02-04T03:44:21.440312Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(\n",
    "    train_iters, eval_iters, losses, js_dists, obs, theo_obs, figsize=(10, 8)\n",
    "):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=figsize)\n",
    "\n",
    "    ax[0].scatter(train_iters, losses, marker='.', alpha=0.1, c='b', s=5)\n",
    "    ax[0].scatter(eval_iters, losses[eval_iters-1], marker='o', c='r', s=50)\n",
    "    ax[0].set_ylabel('Training Loss')\n",
    "    ax[0].set_xlabel('Nth Iteration')\n",
    "\n",
    "\n",
    "    ax[1].plot(eval_iters, js_dists[1:], marker='o')\n",
    "    ax[1].plot(0, js_dists[0], marker='*', c='r')\n",
    "    ax[1].set_ylabel('Jensen–Shannon Distance')\n",
    "    ax[1].set_xlabel('Nth Iteration')\n",
    "    ax[1].set_ylim(0, 1)\n",
    "\n",
    "    ax[2].plot(eval_iters, obs[1:], marker='o')\n",
    "    ax[2].plot(0, obs[0], marker='*', c='r')\n",
    "    ax[2].fill_between(\n",
    "        x=[0, eval_iters[-1]], y1=1.1*theo_obs, y2=0.9*theo_obs, \n",
    "        alpha=0.1, color='k'\n",
    "    )\n",
    "    ax[2].hlines(theo_obs, 0, eval_iters[-1], linestyles='dashed', colors='k')\n",
    "\n",
    "\n",
    "    ax[2].set_ylabel('Average Dihedral Angle')\n",
    "    ax[2].set_xlabel('Nth Iteration')\n",
    "    ax[2].set_ylim(-0.95, 0.6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "training_iterations = np.arange(n_iterations) + 1\n",
    "evaluation_iterations = np.arange(\n",
    "    evaluate_every_n_iterations, \n",
    "    n_iterations+1,\n",
    "    evaluate_every_n_iterations\n",
    ")\n",
    "\n",
    "training_losses = ave_losses.numpy()\n",
    "\n",
    "js_distances = distr_js_dists.numpy()\n",
    "\n",
    "observables = agent_obss.numpy()\n",
    "theoretical_obs = runner.env.theoretical_ave_dihedral_angle.numpy()\n",
    "\n",
    "\n",
    "plot_results(\n",
    "    training_iterations, evaluation_iterations, training_losses, \n",
    "    js_distances, observables, theoretical_obs, figsize=(10, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350eeac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108dc8e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T03:57:16.754318Z",
     "start_time": "2023-02-03T03:57:13.504185Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(\n",
    "    train_iters, eval_iters, losses, distr_errs, obs, theo_obs, eval_sizes, \n",
    "    figsize=(10, 8), colors=['b', 'r', 'g', 'y']\n",
    "):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=figsize)\n",
    "\n",
    "    ax[0].scatter(train_iters, losses, marker='.', alpha=0.1, c='b', s=5)\n",
    "    ax[0].scatter(eval_iters, losses[eval_iters-1], marker='o', c='r', s=50)\n",
    "    ax[0].set_ylabel('Training Loss')\n",
    "    ax[0].set_xlabel('Nth Iteration')\n",
    "\n",
    "    for ind in range(len(eval_sizes)):\n",
    "        ax[1].plot(\n",
    "            eval_iters, distr_errs[1:, ind], \n",
    "            label=f\"Evaluation batch size = {eval_sizes[ind]}\",\n",
    "            marker='o', color=colors[ind]\n",
    "        )\n",
    "        ax[1].plot(0, distr_errs[0, ind], marker='*', color=colors[ind])\n",
    "\n",
    "#         frac_error = np.abs(obs - theo_obs) / np.abs(theo_obs)\n",
    "        \n",
    "        ax[2].plot(\n",
    "            eval_iters, obs[1:, ind], \n",
    "            label=f\"Evaluation batch size = {eval_sizes[ind]}\",\n",
    "            marker='o', color=colors[ind]\n",
    "        )\n",
    "        ax[2].plot(0, obs[0, ind], marker='*', color=colors[ind])\n",
    "        ax[2].hlines(\n",
    "            theo_obs, 0, eval_iters[-1], \n",
    "            linestyles='dashed', colors='k'\n",
    "        )\n",
    "\n",
    "    ax[1].set_ylabel('Average Distribution Error')\n",
    "    ax[1].set_xlabel('Nth Iteration')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    ax[2].set_ylabel('Average Dihedral Angle')\n",
    "    ax[2].set_xlabel('Nth Iteration')\n",
    "    ax[2].set_ylim(-0.95, 0.55)\n",
    "    ax[2].legend(prop={\"size\": 7})\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_results(\n",
    "    training_iterations, evaluation_iterations, training_losses, \n",
    "    distribution_errors, observables, theoretical_obs, eval_batch_sizes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c800d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c48fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T20:45:56.355701Z",
     "start_time": "2023-02-01T20:45:55.914122Z"
    }
   },
   "outputs": [],
   "source": [
    "frac_error = np.abs(observables[1:, -1] - theoretical_obs) / np.abs(theoretical_obs)\n",
    "plt.plot(frac_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734ce1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d9323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cabb8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d6e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T18:44:08.580812Z",
     "start_time": "2023-02-01T18:44:08.565212Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=None, dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=None, dtype=tf.int32)\n",
    "])\n",
    "def test_fn(n_iter, sizes):\n",
    "    observables = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    for i in tf.range(n_iter):\n",
    "        \n",
    "        obs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "        j = 0\n",
    "        for size in sizes:\n",
    "            obs = obs.write(j, tf.cast(i + size, dtype=tf.float32))\n",
    "            j += 1\n",
    "\n",
    "        observables = observables.write(i, obs.stack())\n",
    "        \n",
    "    observables = observables.stack()\n",
    "    return observables\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb217c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T18:44:10.334634Z",
     "start_time": "2023-02-01T18:44:09.616167Z"
    }
   },
   "outputs": [],
   "source": [
    "test_fn(tf.constant(10), tf.constant([500, 1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9588767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622bd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340198c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442643b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T17:06:42.840629Z",
     "start_time": "2023-02-01T17:06:42.358721Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_iters = np.arange(n_iterations) + 1\n",
    "eval_iters = np.arange(\n",
    "    evaluate_every_n_iterations, \n",
    "    n_iterations+1,\n",
    "    evaluate_every_n_iterations\n",
    ")\n",
    "\n",
    "losses = ave_losses.numpy()\n",
    "plt.scatter(train_iters, losses, marker='.', alpha=0.1, c='b', s=5)\n",
    "plt.scatter(eval_iters, losses[eval_iters-1], marker='o', c='r', s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b114264",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T17:12:10.501985Z",
     "start_time": "2023-02-01T17:12:10.065484Z"
    }
   },
   "outputs": [],
   "source": [
    "obs = agent_obss.numpy()\n",
    "theo_obs = runner.env.theoretical_ave_dihedral_angle.numpy()\n",
    "\n",
    "plt.plot(eval_iters, obs)\n",
    "plt.hlines(\n",
    "    theo_obs, eval_iters[0], eval_iters[-1], linestyles='dashed', colors='k'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06993a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T17:15:48.160405Z",
     "start_time": "2023-02-01T17:15:47.767888Z"
    }
   },
   "outputs": [],
   "source": [
    "frac_error = np.abs(obs - theo_obs) / np.abs(theo_obs)\n",
    "\n",
    "plt.plot(eval_iters, frac_error)\n",
    "plt.hlines(\n",
    "    0, eval_iters[0], eval_iters[-1], linestyles='dashed', colors='k'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf14d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab99d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44a5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19893c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1426c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T16:36:40.858377Z",
     "start_time": "2023-02-01T16:36:40.406276Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iters = tf.range(n_iterations) + 1\n",
    "eval_iters = tf.range(\n",
    "    start=evaluate_every_n_iterations, \n",
    "    limit=n_iterations+1, delta=evaluate_every_n_iterations\n",
    ")\n",
    "\n",
    "plt.scatter(train_iters.numpy(), ave_losses.numpy(), marker='.', alpha=0.4)\n",
    "plt.scatter(eval_iters.numpy(), ave_losses.numpy(), marker='.', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d479286",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724ee5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T16:45:30.973313Z",
     "start_time": "2023-02-01T16:45:30.951382Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tf.gather(ave_losses, eval_iters - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7e829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c901266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T16:42:20.549671Z",
     "start_time": "2023-02-01T16:42:20.535733Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.where(tf.math.equal(tf.math.floormod(train_iters, evaluate_every_n_iterations), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb885122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67451f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393d8a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T19:04:25.063056Z",
     "start_time": "2023-01-20T19:04:22.567717Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sq_a = runner.env.squared_amplitudes.numpy().ravel()\n",
    "rewards = runner.env.rewards.numpy().ravel()\n",
    "\n",
    "plt.hist(sq_a, bins=200);\n",
    "plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf83bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:29:18.551858Z",
     "start_time": "2023-01-20T18:29:17.259439Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(rewards, bins=200);\n",
    "plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd86283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T19:09:32.790723Z",
     "start_time": "2023-01-20T19:04:25.072253Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "half_batch_size = tf.constant(500)\n",
    "n_iterations = tf.constant(int(2e3))\n",
    "# n_iterations = tf.constant(500)\n",
    "evaluate_every_n_iterations = tf.constant(int(1e2))\n",
    "evaluation_batch_size = tf.constant(int(5e4))\n",
    "\n",
    "start = time.time()\n",
    "ave_losses, ave_distr_errors, agent_obs = runner.train_agent(\n",
    "    half_batch_size, n_iterations, evaluate_every_n_iterations, evaluation_batch_size\n",
    ")\n",
    "time_elapsed = time.time() - start\n",
    "print(f\"Time Elapsed: {time_elapsed} s\")\n",
    "print(f\"Average loss of last iteration: {float(ave_losses[-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51be370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T19:09:36.976538Z",
     "start_time": "2023-01-20T19:09:36.555885Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ave_losses.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28907d6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T19:09:40.199607Z",
     "start_time": "2023-01-20T19:09:39.756872Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(ave_distr_errors.numpy())\n",
    "# ave_distr_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e502e3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T19:09:43.533672Z",
     "start_time": "2023-01-20T19:09:43.117685Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(agent_obs.numpy())\n",
    "plt.hlines(\n",
    "    runner.env.theoretical_ave_dihedral_angle.numpy(),\n",
    "    0, len(agent_obs) - 1, linestyles='dashed', colors='k'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61ea70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:59:26.513033Z",
     "start_time": "2023-01-20T18:59:26.491580Z"
    }
   },
   "outputs": [],
   "source": [
    "runner.env.theoretical_ave_dihedral_angle.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25c801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0920f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff284fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T04:07:41.672170Z",
     "start_time": "2022-12-15T04:07:41.657367Z"
    }
   },
   "outputs": [],
   "source": [
    "env_distr = runner.env.rewards / tf.math.reduce_sum(runner.env.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811c5ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T04:19:05.572145Z",
     "start_time": "2022-12-15T04:19:05.537145Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _plot_l1_errors_per_probability_interval(agent_prob, env_prob, \n",
    "#                                              filename, \n",
    "                                             n_intervals\n",
    "                                            ):\n",
    "    result = agent_prob.ravel()\n",
    "    expected = env_prob.ravel()\n",
    "    max_expected = expected.max()\n",
    "    expected_pcts = expected * 100 / max_expected\n",
    "\n",
    "    interval_edges = np.linspace(0, 100, n_intervals + 1)\n",
    "    starts = interval_edges[:-1]\n",
    "    ends = interval_edges[1:]\n",
    "\n",
    "#     frac_l1_errors = np.abs(result - expected) / max_expected\n",
    "    l1_errors = np.abs(result - expected)\n",
    "    errors = []\n",
    "    labels = []\n",
    "    for s, e in zip(starts, ends):\n",
    "        inds = np.where((s < expected_pcts) & (expected_pcts <= e))\n",
    "#         errors_per_interval = frac_l1_errors[inds]\n",
    "        errors_per_interval = l1_errors[inds]\n",
    "        if len(errors_per_interval):\n",
    "            interval_label = f\"{s:.2f}% < pct <= {e:.2f}%\"\n",
    "            max_expected_per_interval = expected[inds].max()\n",
    "            errors.append(errors_per_interval / max_expected_per_interval)\n",
    "            labels.append(interval_label)\n",
    "\n",
    "#     print(errors)\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.violinplot(errors)\n",
    "    ax.set_xticks(np.arange(1, len(labels) + 1), labels=labels, rotation=15)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_ylabel(\"Fractional L1 Errors\")\n",
    "    ax.set_xlabel(\"Percentage of max theoretical probability\")\n",
    "    plt.tight_layout()\n",
    "#     fig.savefig(f\"./plot_results/{filename}\")\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ce627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T04:19:19.807341Z",
     "start_time": "2022-12-15T04:19:07.634930Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = tf.constant(int(5e4))\n",
    "\n",
    "agent_distr = runner.get_normalized_agent_sample_distribution(batch_size)\n",
    "\n",
    "grid_dim = 5\n",
    "n_unique_samples = tf.shape(tf.where(agent_distr))[0]\n",
    "frac_unique_coords = n_unique_samples / (grid_length ** grid_dim)\n",
    "print(f\"Percentage of coordinates sampled uniquely: {float(frac_unique_coords*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc8d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T04:19:23.618566Z",
     "start_time": "2022-12-15T04:19:22.914552Z"
    }
   },
   "outputs": [],
   "source": [
    "errors = _plot_l1_errors_per_probability_interval(\n",
    "    agent_distr.numpy(), env_distr.numpy(), n_intervals=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913999bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T04:19:53.212950Z",
     "start_time": "2022-12-15T04:19:31.773505Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = tf.constant(int(1e5))\n",
    "\n",
    "agent_distr = runner.get_normalized_agent_sample_distribution(batch_size)\n",
    "\n",
    "grid_dim = 5\n",
    "n_unique_samples = tf.shape(tf.where(agent_distr))[0]\n",
    "frac_unique_coords = n_unique_samples / (grid_length ** grid_dim)\n",
    "print(f\"Percentage of coordinates sampled uniquely: {float(frac_unique_coords*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2bc0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T04:19:58.987829Z",
     "start_time": "2022-12-15T04:19:58.123144Z"
    }
   },
   "outputs": [],
   "source": [
    "errors = _plot_l1_errors_per_probability_interval(\n",
    "    agent_distr.numpy(), env_distr.numpy(), n_intervals=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f22be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T04:23:40.226194Z",
     "start_time": "2022-12-15T04:20:40.351748Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = tf.constant(int(5e5))\n",
    "\n",
    "agent_distr = runner.get_normalized_agent_sample_distribution(batch_size)\n",
    "\n",
    "grid_dim = 5\n",
    "n_unique_samples = tf.shape(tf.where(agent_distr))[0]\n",
    "frac_unique_coords = n_unique_samples / (grid_length ** grid_dim)\n",
    "print(f\"Percentage of coordinates sampled uniquely: {float(frac_unique_coords*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e8f96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T04:24:25.300001Z",
     "start_time": "2022-12-15T04:24:24.275844Z"
    }
   },
   "outputs": [],
   "source": [
    "errors = _plot_l1_errors_per_probability_interval(\n",
    "    agent_distr.numpy(), env_distr.numpy(), n_intervals=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2cace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
